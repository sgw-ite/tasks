{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import Feature_Engineering\n",
    "import metrics\n",
    "import train_test_split as tts\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = './train.csv'\n",
    "X_train, y_train = Feature_Engineering.datatransform(file)\n",
    "X_train, y_train, X_test, y_test = tts.holdout(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = y_train.reshape((-1,1))\n",
    "Y_test = y_test.reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(622, 14) (267, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class layer():\n",
    "    \n",
    "    '''\n",
    "    层。\n",
    "    储存W,b,A,Z矩阵。\n",
    "    提供forward（激活），backward（计算在输入值处的激活函数的导数）接口。\n",
    "    -----\n",
    "    params:\n",
    "    Z : 输入值组成的矩阵。shape=(样本个数，本层节点个数)\n",
    "    A : 激活值组成的矩阵。shape同Z\n",
    "    B : 偏置单元\n",
    "    dZ : 残差用于更新W\n",
    "    dgZ : 激活函数在z点的导数值\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, method='test', nodenum=0, nextnodenum=0, size=0):\n",
    "        \n",
    "        self.method = method\n",
    "        self.nodenum = nodenum\n",
    "        self.nextnodenum = nextnodenum\n",
    "        self.size = size\n",
    "        self.W = np.ones((self.nodenum,self.nextnodenum))\n",
    "        for i in range(self.nodenum):\n",
    "            for j in range(self.nextnodenum):\n",
    "                self.W[i][j] = np.random.random(1) ############### 直接用 np.random.random((self.nodenum, self.nextnodenum))\n",
    "        #print(self.nextnodenum)\n",
    "        self.b = np.ones((1,self.nextnodenum))\n",
    "        for i in range(self.nextnodenum):\n",
    "            self.b[0][i] = np.random.random(1)\n",
    "        self.Z = np.ones((self.size,self.nodenum))\n",
    "        for i in range(size):\n",
    "            for j in range(self.nodenum):\n",
    "                self.Z[i][j] = np.random.random(1)\n",
    "        self.A = self.Z.copy()\n",
    "        self.dZ = self.Z.copy()\n",
    "        self.dgZ = self.Z.copy()\n",
    "        self.B = np.ones((size,1))\n",
    "        \n",
    "    def _ReLU(self, Z, direction):\n",
    "        if direction=='forward':\n",
    "            for i in range(Z.shape[0]): ############### np.clip(Z, 0)\n",
    "                for j in range(Z.shape[1]):\n",
    "                    if Z[i][j]<=0:\n",
    "                        Z[i][j] = 0\n",
    "            return Z\n",
    "        for i in range(Z.shape[0]):\n",
    "                for j in range(Z.shape[1]):\n",
    "                    if Z[i][j]<=0:\n",
    "                        Z[i][j] = 0\n",
    "                    else: \n",
    "                        Z[i][j] = 1\n",
    "        return Z\n",
    "    \n",
    "    def _sigmoid(self, z, direction):\n",
    "        haha = (1 / (1 + np.exp(-z)))\n",
    "        if direction=='forward':\n",
    "            return haha\n",
    "        return haha*(1-haha)\n",
    "    \n",
    "    def _tanh(self, z, direction):\n",
    "        if direction=='forward':\n",
    "            return ((np.exp(2*z) - 1) / (np.exp(2*z) +1))\n",
    "        return (4 * (np.exp(2*z) / ((np.exp(2*z) + 1)**2)))\n",
    "    \n",
    "    def _test(self, z, direction):\n",
    "        if direction=='forward':\n",
    "            return z\n",
    "        return 1\n",
    "    \n",
    "        \n",
    "    def forward(self):\n",
    "        \n",
    "        if self.method=='ReLU':\n",
    "            self.A = self._ReLU(self.Z, direction='forward')\n",
    "        elif self.method=='sigmoid':\n",
    "            self.A = self._sigmoid(self.Z, direction='forward')\n",
    "        elif self.method=='tanh':\n",
    "            self.A = self._tanh(self.Z, direction='forward')\n",
    "        elif self.method=='test':\n",
    "            self.A = self._test(self.Z, direction='forward')\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def backward(self):\n",
    "        \n",
    "        if self.method=='ReLU':\n",
    "            self.dgZ = self._ReLU(self.Z, direction='backward')\n",
    "        elif self.method=='sigmoid':\n",
    "            self.dgZ = self._sigmoid(self.Z, direction='backward')\n",
    "        elif self.method=='tanh':\n",
    "            self.dgZ = self._tanh(self.Z, direction='backward')\n",
    "        elif self.method=='test':\n",
    "            self.dgZ = self._test(self.Z, direction='backward')\n",
    "        return self\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class neuralnetwork():\n",
    "    \n",
    "    def __init__(self, X_train, Y_train, layer_num=3, eta=0.5, lamda=0.1):\n",
    "        self.X_train = X_train\n",
    "        self.Y_train = Y_train\n",
    "        self.layer_num = layer_num\n",
    "        self.eta = eta\n",
    "        self.lamda = lamda\n",
    "        #构建网络\n",
    "        self.size = self.X_train.shape[0]\n",
    "        self.layers = []\n",
    "        #输入层：\n",
    "        inlayer = layer(nodenum=X_train.shape[1], nextnodenum=20, size=self.size)\n",
    "        self.layers.append(inlayer)\n",
    "        self.__iter = 0\n",
    "        #隐藏层：\n",
    "        if self.layer_num==3:\n",
    "            hidlayer = layer(nodenum=20, nextnodenum=self.Y_train.shape[1], size=self.size)\n",
    "            ####################### 这里多了一个输出层，注释了就好了，你看看到底是哪里写错了吧（\n",
    "            #outlayer = layer(nodenum=self.Y_train.shape[1], nextnodenum=self.Y_train.shape[1], size=self.size, method='sigmoid')#nextnodenum无意义\n",
    "            self.layers.append(hidlayer)\n",
    "            #self.layers.append(outlayer)\n",
    "        else:\n",
    "            for i in range(self.layer_num-3):\n",
    "                hidlayer = layer(nodenum=20, nextnodenum=20, size=self.size)\n",
    "                self.layers.append(hidlayer)\n",
    "            hidlayer = layer(nodenum=20, nextnodenum=self.Y_train.shape[1], size=self.size)\n",
    "        #输出层：\n",
    "        outlayer = layer(nodenum=self.Y_train.shape[1], nextnodenum=2, size=self.size, method='sigmoid') #nextnodenum无意义\n",
    "        self.layers.append(outlayer)\n",
    "        #网络构建完毕。\n",
    "    \n",
    "    def forward(self):\n",
    "        \n",
    "        #对第一层：\n",
    "        self.layers[0].A = self.X_train.copy()\n",
    "        \n",
    "        #接下来的每一层：\n",
    "        for i in range(self.layer_num-1):\n",
    "            self.layers[i+1].Z = self.layers[i].A.dot(self.layers[i].W) + self.layers[i].B.dot(self.layers[i].b)\n",
    "            self.layers[i+1].forward()\n",
    "        #print('3',self.layers[num-2-i].W)\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def backward(self):\n",
    "        \n",
    "        # 从输出层开始：\n",
    "        self.layers[-1].backward()\n",
    "        self.layers[-1].dZ = (self.layers[-1].A - self.Y_train) * (self.layers[-1].dgZ)\n",
    "        \n",
    "        # 依次往后传播,计算dz：\n",
    "        num = self.layer_num #为了下面的代码简洁一点\n",
    "        for i in range(num-1):\n",
    "            self.layers[num-2-i].backward()\n",
    "            self.layers[num-2-i].dZ = self.layers[num-1-i].dZ.dot(self.layers[num-2-i].W.T) * self.layers[num-2-i].dgZ\n",
    "            \n",
    "        # 更新W,b：\n",
    "        \n",
    "        for i in range(num-1):\n",
    "            dW = (self.layers[num-2-i].W * self.lamda) + ((self.layers[num-2-i].A.T.dot(self.layers[num-1-i].dZ)) / self.size)\n",
    "            db = np.sum((self.layers[num-1-i].dZ / self.size), axis=0).reshape(1,-1)\n",
    "            if self.__iter%10==0:\n",
    "                print('layer :',i,'\\ndW:',dW[:3,:3],'\\ndb:',db[:3],'\\n',self.__iter)\n",
    "            #print('1',self.layers[num-2-i].W)\n",
    "            self.layers[num-2-i].W = self.layers[num-2-i].W - (self.eta * dW)\n",
    "            #print('2',self.layers[num-2-i].b)\n",
    "            self.layers[num-2-i].b = self.layers[num-2-i].b - (self.eta * db)\n",
    "            \n",
    "        self.__iter += 1\n",
    "        \n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetworkClassifier():\n",
    "    \n",
    "    def __init__(self, network, X_train, Y_train, eta=0.5, lamda=0.1, epsilon=1e-4):\n",
    "        self.network = network\n",
    "        self.X_train = X_train\n",
    "        self.Y_train = Y_train\n",
    "        self.eta = eta\n",
    "        self.epsilon = epsilon\n",
    "        self.lamda = lamda\n",
    "        self.mynetwork = neuralnetwork(self.X_train, self.Y_train)\n",
    "        \n",
    "    def _J(self, network, Y_train):\n",
    "        y_pred = network.layers[-1].A\n",
    "        W2 = 0\n",
    "        for i in range(network.layer_num):\n",
    "            W2 += np.sum(network.layers[i].W ** 2)\n",
    "        J = 0.5 * np.sum((Y_train - y_pred)**2) + self.lamda * 0.5 * W2\n",
    "        return J\n",
    "        \n",
    "    def fit(self):\n",
    "        self.mynetwork.forward()\n",
    "        _iter = 0\n",
    "        #y_pred = mynetwork.layers[-1].A\n",
    "        while(_iter<1000):\n",
    "            J1 = self._J(Y_train=self.Y_train, network=self.mynetwork)\n",
    "            self.mynetwork.backward()\n",
    "            self.mynetwork.forward()\n",
    "            J2 = self._J(Y_train=self.Y_train, network=self.mynetwork)\n",
    "            #print('4',self.mynetwork.layers[0].W, mynetwork2.layers[0].W)\n",
    "            print(J1)\n",
    "            delta = J1 -J2\n",
    "            \n",
    "            if (delta) < self.epsilon: ########### 之前给delta加了abs，不应该加\n",
    "                break\n",
    "            \n",
    "            _iter += 1\n",
    "            if _iter%50==0:\n",
    "                print('\\ndelta=',delta)\n",
    "        \n",
    "        \n",
    "    def predict(self, X_test, Y_test):\n",
    "        self.newnetwork = neuralnetwork(X_train=X_test, Y_train=Y_test)\n",
    "        for i in range(self.newnetwork.layer_num):\n",
    "            self.newnetwork.layers[i].W = self.mynetwork.layers[i].W.copy()\n",
    "            self.newnetwork.layers[i].b = self.mynetwork.layers[i].b.copy()\n",
    "        self.newnetwork.forward()\n",
    "        y_pred = self.newnetwork.layers[-1].A\n",
    "        return np.array(y_pred>0.5, dtype='int')\n",
    "    \n",
    "    def score(self, X_test, Y_test, scoring=metrics.acc_score):\n",
    "        y_pred = self.predict(X_test,Y_test).reshape(-1,).astype('float64')\n",
    "        y_test = Y_test.reshape(-1,)\n",
    "        print(y_pred, '1', y_test)\n",
    "        return scoring(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer : 0 \n",
      "dW: [[0.03451173]\n",
      " [0.04313441]\n",
      " [0.10007772]] \n",
      "db: [[0.00610534]] \n",
      " 0\n",
      "layer : 1 \n",
      "dW: [[0.08583717 0.01929017 0.07859025]\n",
      " [0.05617943 0.09532744 0.03585864]\n",
      " [0.03490155 0.03059819 0.05616403]] \n",
      "db: [[0.00181581 0.00249679 0.00607429 0.00583967 0.0058179  0.00563118\n",
      "  0.00493673 0.0017669  0.00528832 0.00567335 0.00314871 0.00520634\n",
      "  0.00344589 0.00119412 0.00086279 0.00412309 0.0008749  0.00351662\n",
      "  0.00013963 0.0037975 ]] \n",
      " 0\n",
      "117.49564112589744\n",
      "117.26704213855587\n",
      "117.06805062185948\n",
      "116.83796504999168\n",
      "116.53407284099569\n",
      "116.13287184296397\n",
      "115.62665627173604\n",
      "115.01554089033583\n",
      "114.29724865447939\n",
      "113.45882342414296\n",
      "layer : 0 \n",
      "dW: [[0.02724945]\n",
      " [0.03136007]\n",
      " [0.05557984]] \n",
      "db: [[0.02112713]] \n",
      " 10\n",
      "layer : 1 \n",
      "dW: [[0.05137843 0.01165971 0.04768011]\n",
      " [0.03320194 0.05638497 0.01953647]\n",
      " [0.02064949 0.01780341 0.03188936]] \n",
      "db: [[ 3.15027085e-03  4.75752420e-03  1.27048949e-02  1.14849100e-02\n",
      "   1.22325859e-02  1.15983463e-02  9.56085078e-03  3.51483399e-03\n",
      "   1.14098467e-02  1.19662530e-02  6.88073410e-03  1.04988444e-02\n",
      "   6.78000821e-03  1.53263702e-03  1.78350104e-03  8.20157273e-03\n",
      "   1.51117161e-03  7.58208546e-03 -1.47314854e-05  6.98992760e-03]] \n",
      " 10\n",
      "112.4734129718512\n",
      "111.30215332508313\n",
      "109.89881937258708\n",
      "108.21496334228016\n",
      "106.20451712163386\n",
      "103.82780203493702\n",
      "101.05544486540575\n",
      "97.87296140646546\n",
      "94.2866155035331\n",
      "90.33067017820733\n",
      "layer : 0 \n",
      "dW: [[0.03157125]\n",
      " [0.02997085]\n",
      " [0.0311967 ]] \n",
      "db: [[0.04156958]] \n",
      " 20\n",
      "layer : 1 \n",
      "dW: [[0.02981429 0.00644897 0.0297708 ]\n",
      " [0.02054449 0.03465128 0.01374637]\n",
      " [0.01364043 0.01196391 0.02074344]] \n",
      "db: [[ 0.00011514  0.00299364  0.01629376  0.01041539  0.014872    0.01243894\n",
      "   0.00751263  0.00333053  0.01489094  0.01436313  0.00967894  0.01082458\n",
      "   0.0058196  -0.00296768  0.00145371  0.00696644 -0.0010103   0.01006904\n",
      "  -0.00160082  0.00404745]] \n",
      " 20\n",
      "86.07560938206751\n",
      "81.63625095932782\n",
      "77.17689465505477\n",
      "72.90677272089343\n",
      "69.05561836665491\n",
      "65.82445051426852\n",
      "63.32688578894914\n",
      "61.556653108199214\n",
      "60.405654006146236\n",
      "59.71747843693553\n",
      "layer : 0 \n",
      "dW: [[0.00469824]\n",
      " [0.00726994]\n",
      " [0.01863797]] \n",
      "db: [[0.01262099]] \n",
      " 30\n",
      "layer : 1 \n",
      "dW: [[0.01700339 0.0027389  0.01513245]\n",
      " [0.0110187  0.02037649 0.01160284]\n",
      " [0.00799465 0.00765745 0.01592488]] \n",
      "db: [[-0.00136    -0.00045524  0.00322781  0.0010793   0.00265258  0.0017657\n",
      "   0.00025005  0.00019261  0.0028393   0.00250812  0.00225993  0.0013692\n",
      "   0.00043783 -0.00198855 -0.00023631  0.00022736 -0.00138843  0.00214664\n",
      "  -0.00086728 -0.00050404]] \n",
      " 30\n",
      "59.34030680597158\n",
      "59.15624392743114\n",
      "59.08639192891516\n",
      "59.0827914083089\n",
      "CPU times: user 206 ms, sys: 19.9 ms, total: 226 ms\n",
      "Wall time: 116 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nnc = NeuralNetworkClassifier(network=neuralnetwork, X_train=X_train, Y_train=Y_train)\n",
    "nnc.fit() # 最好也是能把loss的下降可视化出来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.74437299]\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.array(nnc.mynetwork.layers[-1].A > 0.5, dtype='int')\n",
    "print(sum(y_pred==Y_train)/len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1.\n",
      " 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0.\n",
      " 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0.] 1 [0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0.\n",
      " 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1.\n",
      " 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0.\n",
      " 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1.\n",
      " 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1.\n",
      " 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 1. 1.]\n",
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "print(nnc.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
